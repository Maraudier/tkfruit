{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BF_original.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maraudier/tkfruit/blob/master/BF_original.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JORxfjlfVXuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Colab library to upload files to notebook\n",
        "from google.colab import files\n",
        "\n",
        "# Install Kaggle library\n",
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKmyCMrVvdDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle\n",
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j96AAgU8Ytm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"williamahtou\",\"key\":\"40faa6e3f4d012c9b39cf9e96a731583\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPmpcjS4an2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!chmod 600 /content/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GNJI72sapVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPJlXNYUavxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle config set -n path -v{/content}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1MWepkwbCQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d sriramr/fruits-fresh-and-rotten-for-classification -p /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwHKFIxlbPIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVUhG5TnfeUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/dataset/dataset/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzqrEQB8cM3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_j61Hl1bV4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "# Specifying test and training paths\n",
        "train_dir = pathlib.Path('dataset/train')\n",
        "test_dir = pathlib.Path('dataset/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csiA4LokdIiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Version of tensorflow should be specified in Colab\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z080SiOc0lN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_count = len(list(train_dir.glob('*/*.png'))) + len(list(test_dir.glob('*/*.png')))\n",
        "CLASS_NAMES = np.array([item.name for item in train_dir.glob('*') if item.name != 'LICENSE.txt'])\n",
        "CLASS_NAMES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW-NJ6sbhGMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The 1./255 is to convert from uint8 to float32 in range [0,1]. Split data into 80/20 \n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "# The transformations shear_range, zoom_range, horizontal_flip will improve accuracy across data and allow for more generalized inputs\n",
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "# CONSTANTS, currently unsure what to set IMG_HEIGHT and IMG_WIDTH\n",
        "BATCH_SIZE = 64\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ7vVUSthKRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_data_gen = train_generator.flow_from_directory(directory=str(train_dir),\n",
        "                                                     batch_size=BATCH_SIZE,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode=\"sparse\",\n",
        "                                                     classes = list(CLASS_NAMES))\n",
        "test_data_gen = test_generator.flow_from_directory(directory=str(test_dir),\n",
        "                                                     batch_size=BATCH_SIZE,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode=\"sparse\",\n",
        "                                                     classes = list(CLASS_NAMES))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFfZ30Q1nUGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN architecure\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(.5))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(6, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycy_tKXQntDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4c6RwO0fOjb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup checkpoint callback - will save the model after each epoch if validation loss is lower than the previous checkpoint\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('./', save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCXDUsBeoFyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiler\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the data and validating with test data\n",
        "history = model.fit(\n",
        "        train_data_gen,\n",
        "        epochs=25,\n",
        "        callbacks=[checkpoint],\n",
        "        validation_data=test_data_gen)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDehm7zh7RFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.1, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_data_gen, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtUOsvvDYBgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import base64\n",
        "\n",
        "def save_model_signed(model, path):\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, ], dtype=tf.string)])\n",
        "    def preprocess_and_evaluate(b64_img):\n",
        "        img = tf.image.decode_image(b64_img[0], dtype=tf.uint8)\n",
        "        img.set_shape((None, None, 3))\n",
        "        img = tf.image.resize(img, [128, 128])\n",
        "        img = tf.reshape(img, (-1, 128, 128, 3))\n",
        "        img = tf.cast(img, dtype=tf.float32) / 255\n",
        "\n",
        "\n",
        "        return model(img)\n",
        "    \n",
        "    tf.saved_model.save(model, path, signatures=preprocess_and_evaluate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqDoMpPyaoHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_model_signed(model,'')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}